{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71df38c",
   "metadata": {},
   "source": [
    "\n",
    "# Gender Classification Using CNN and DOE\n",
    "\n",
    "This notebook demonstrates a pipeline for binary gender classification from facial images using Convolutional Neural Networks (CNNs). A Design of Experiments (DOE) approach is used to systematically explore various architectural and training hyperparameters to optimize model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.data_loader import load_datasets\n",
    "from src.model_builder import create_model, get_callbacks\n",
    "from src.training_utils import train_and_evaluate, plot_training_curves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db945449",
   "metadata": {},
   "source": [
    "\n",
    "## Load Dataset\n",
    "\n",
    "We begin by loading the dataset using a custom data loader. The dataset consists of facial portraits labeled by gender. The images have been preprocessed to a uniform size and split into training, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc05438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds, val_ds, test_ds = load_datasets(\"data_path_here\", img_size=130)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500ecb6",
   "metadata": {},
   "source": [
    "\n",
    "## Build and Train the CNN Model\n",
    "\n",
    "We now define a custom CNN architecture with configurable parameters such as learning rate, dropout rate, number of dense units, and number of filters in convolutional layers. These parameters have been optimized based on our DOE analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model(img_size=130, learning_rate=0.0005, dropout=0.2, n_units=4096, filters=(32, 64))\n",
    "history = train_and_evaluate(model, train_ds, val_ds, callbacks=get_callbacks(0.89, 0.89))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90897a7d",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate Model Performance\n",
    "\n",
    "We assess the model's performance using standard classification metrics, including precision, recall, and F1-score. This helps quantify the model's ability to generalize on unseen validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71303960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(val_ds)\n",
    "y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "y_true = np.concatenate([y.numpy() for _, y in val_ds])\n",
    "print(classification_report(y_true, y_pred, target_names=['Female', 'Male']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490c55c",
   "metadata": {},
   "source": [
    "\n",
    "## Visualize Training Progress\n",
    "\n",
    "To better understand the learning behavior, we visualize training and validation accuracy and loss over epochs. This can help diagnose underfitting or overfitting during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca38b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_training_curves(history)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
