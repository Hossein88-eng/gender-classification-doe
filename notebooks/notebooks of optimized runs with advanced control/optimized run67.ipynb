{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40aaebb4-037c-4ca4-a4c7-b63f03b071b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe0da97-852e-4243-a988-848082ac2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default initial values of DOE factors:\n",
    "# learning_rate = 0.001\n",
    "# dropout_value = 0.3\n",
    "# #n-conv_layers = 3\n",
    "# n_units_last_layer = 2048\n",
    "# n_filters_l1 = 32\n",
    "# n_filters_l2 = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e168a015-372f-4ba6-be82-501458ed9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOE factors:\n",
    "learning_rate = 0.001\n",
    "dropout_value = 0.3\n",
    "# n-conv_layers = 5\n",
    "n_units_last_layer = 2048\n",
    "n_filters_l1 = 16\n",
    "n_filters_l2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f023191-b81d-488e-bcf7-47cb6de0ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other factors:\n",
    "img_size = 130\n",
    "batch_size = 32\n",
    "validation_split = 0.1  # 10% for validation\n",
    "test_split = 0.00  # 0% for testing\n",
    "shuffle_buffer_size = 1000\n",
    "seed_num = 101\n",
    "desired_accuracy = 0.99  # it should be active if EarlyStoppingCallback is activated\n",
    "loss = 'binary_crossentropy'\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "metrics = ['accuracy']\n",
    "epochs = 100\n",
    "f_mode = 'nearest'  # fill_mode in image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4c91d-2f8f-4aad-8f3d-b5c4083437ab",
   "metadata": {},
   "source": [
    "    My dataset_root/\n",
    "    ├── woman/\n",
    "    │   ├── woman_1.jpg\n",
    "    │   ├── woman_2.jpg\n",
    "    │   ├── ...\n",
    "    ├── man/\n",
    "    │   ├── man_1.jpg\n",
    "    │   ├── man_2.jpg\n",
    "    │   ├── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63419a3-8c4c-420c-a1ee-81d06c316f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 471 images of woman.\n",
      "There are 472 images of man.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"D:\\\\CS online courses\\\\Free DataSets\\\\Free Images\\\\Easier portrait images_GPU_03\"\n",
    "\n",
    "# Subdirectories for each class\n",
    "data_dir_woman = os.path.join(DATA_DIR, 'woman')\n",
    "data_dir_man = os.path.join(DATA_DIR, 'man')\n",
    "\n",
    "# os.listdir returns a list containing all files under the given dir\n",
    "print(f\"There are {len(os.listdir(data_dir_woman))} images of woman.\")\n",
    "print(f\"There are {len(os.listdir(data_dir_man))} images of man.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0d2806-2487-4ac5-97c4-ff2210416dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 943 files belonging to 2 classes.\n",
      "Using 849 files for training.\n",
      "Found 943 files belonging to 2 classes.\n",
      "Using 94 files for validation.\n",
      "Train batches: 27\n",
      "Validation batches: 3\n",
      "Test batches: 0\n"
     ]
    }
   ],
   "source": [
    "image_size = (img_size, img_size)  # Resize images to this size\n",
    "\n",
    "# Load train dataset (excluding validation & test set):\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = DATA_DIR,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    label_mode='binary',\n",
    "    validation_split = validation_split + test_split,  # Total split for val + test\n",
    "    subset = \"training\",\n",
    "    seed = seed_num\n",
    ")\n",
    "\n",
    "# Load validation dataset\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = DATA_DIR,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    label_mode='binary',\n",
    "    validation_split = validation_split + test_split,\n",
    "    subset = \"validation\",\n",
    "    seed = seed_num\n",
    ")\n",
    "\n",
    "# Further manually split validation dataset to extract test dataset\n",
    "val_batches = tf.data.experimental.cardinality(val_dataset)\n",
    "# Compute test dataset size (number of batches)\n",
    "test_size = round(val_batches.numpy() * (test_split / (validation_split + test_split)))\n",
    "# Split validation dataset into validation and test subsets\n",
    "test_dataset = val_dataset.take(test_size)\n",
    "val_dataset = val_dataset.skip(test_size)\n",
    "\n",
    "\n",
    "print(f\"Train batches: {tf.data.experimental.cardinality(train_dataset).numpy()}\")\n",
    "print(f\"Validation batches: {tf.data.experimental.cardinality(val_dataset).numpy()}\")\n",
    "print(f\"Test batches: {tf.data.experimental.cardinality(test_dataset).numpy()}\")\n",
    "\n",
    "# Optimize for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "training_dataset = train_dataset.cache().shuffle(shuffle_buffer_size).prefetch(buffer_size = AUTOTUNE)\n",
    "validation_dataset = val_dataset.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d9e533-9ca2-45af-af85-a7e030fa184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value of images: 255.0\n",
      "\n",
      "Shape of batch of images: (32, 130, 130, 3)\n",
      "Shape of batch of labels: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch of images and labels\n",
    "for images, labels in training_dataset.take(1):\n",
    "\texample_batch_images = images\n",
    "\texample_batch_labels = labels\n",
    "\n",
    "max_pixel = np.max(example_batch_images)\n",
    "print(f\"Maximum pixel value of images: {max_pixel}\\n\")\n",
    "print(f\"Shape of batch of images: {example_batch_images.shape}\")\n",
    "print(f\"Shape of batch of labels: {example_batch_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85453247-adf0-4e7d-8924-f86415759f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass EarlyStoppingCallback(tf.keras.callbacks.Callback):\\n    def on_epoch_end(self, epoch, logs=None):\\n        train_accuracy = logs.get(\\'accuracy\\')\\n        val_accuracy = logs.get(\\'val_accuracy\\')\\n        if train_accuracy >= desired_accuracy and val_accuracy >= desired_accuracy:\\n            self.model.stop_training = True\\n            print(f\"\\nReached {desired_accuracy}% accuracy so cancelling training!\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_accuracy = logs.get('accuracy')\n",
    "        val_accuracy = logs.get('val_accuracy')\n",
    "        if train_accuracy >= desired_accuracy and val_accuracy >= desired_accuracy:\n",
    "            self.model.stop_training = True\n",
    "            print(f\"\\nReached {desired_accuracy}% accuracy so cancelling training!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7906f3e8-d63c-4210-b096-5ee54e2c1895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom tensorflow.keras.callbacks import EarlyStopping\\nearly_stop = EarlyStopping(monitor='val_loss', patience=3)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7fe37b-3831-478d-9fd5-d018ce786472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Reduce LR every 10 epochs (Learning rate decay factor)\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 20:\n",
    "        if epoch < 15:\n",
    "            if epoch % 10 == 0 and epoch > 0:\n",
    "                #return lr * 0.1\n",
    "                return lr / 2\n",
    "            return lr\n",
    "        elif epoch % 10 == 0 and epoch > 0:\n",
    "            #return lr * 0.1\n",
    "            return lr / 5\n",
    "        return lr\n",
    "    elif epoch % 10 == 0 and epoch > 0:\n",
    "        #return lr * 0.1\n",
    "        return lr / 10\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06db003d-e408-472a-986b-54e0728db183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation_model\n",
    "def augment_model():\n",
    "    \"\"\"Creates a model (layers stacked on top of each other) for augmenting images of woman and man.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The model made up of the layers that will be used to augment the images of woman and man.\n",
    "    \"\"\"\n",
    "\n",
    "    augmentation_model = tf.keras.Sequential([\n",
    "        # Specify the input shape.\n",
    "        tf.keras.Input(shape = (img_size, img_size, 3)),\n",
    "        \n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1, fill_mode = f_mode),\n",
    "        #tf.keras.layers.RandomTranslation(0.1, 0.1, fill_mode = f_mode),\n",
    "        #tf.keras.layers.RandomZoom(0.1, fill_mode=f_mode)\n",
    "        ])\n",
    "\n",
    "    return augmentation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d8ea70-8df3-4dd5-93e0-013cd42546e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_compile_model():\n",
    "    \"\"\"Creates, compiles and trains the model to predict woman and man images.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The model that will be trained to predict woman and man images.\n",
    "    \"\"\"\n",
    "\n",
    "    augmentation_layers = augment_model()\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        # Note: the input shape is the desired size of the image: 150x150 with 3 bytes for color\n",
    "        tf.keras.layers.InputLayer(shape = (img_size, img_size, 3)),\n",
    "        augmentation_layers,\n",
    "        tf.keras.layers.Rescaling(1./255),\n",
    "        #####    CONV_LAYER_1:     #####\n",
    "        tf.keras.layers.Conv2D(n_filters_l1, (4, 4), activation = 'linear'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        #####    CONV_LAYER_2:     #####\n",
    "        tf.keras.layers.Conv2D(n_filters_l2, (3, 3), activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        #####    CONV_LAYER_3:     #####\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        #####    CONV_LAYER_4:     #####\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        #####    CONV_LAYER_5:     #####\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(dropout_value),\n",
    "        #####    BEFORE_LAST_LAYER:     #####\n",
    "        tf.keras.layers.Dense(n_units_last_layer, activation = 'relu'),\n",
    "        # It will contain a value from 0-1 where 0 for the class 'female' and 1 for the 'male'\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
    "\n",
    "    model.compile(\n",
    "        loss = loss,\n",
    "        optimizer = optimizer,\n",
    "        metrics = metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ecc4042-af60-4d6a-a989-f81761b5bc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">526,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │       \u001b[38;5;34m526,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">626,161</span> (2.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m626,161\u001b[0m (2.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">626,161</span> (2.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m626,161\u001b[0m (2.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the compiled but untrained model\n",
    "model = create_and_compile_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89abb112-31e4-462d-aeb5-ac878eb84cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining_history = model.fit(\\n    training_dataset,\\n    epochs = epochs,\\n    validation_data = validation_dataset,\\n    callbacks = [EarlyStoppingCallback()],\\n    verbose = 2\\n)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "training_history = model.fit(\n",
    "    training_dataset,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_dataset,\n",
    "    callbacks = [EarlyStoppingCallback()],\n",
    "    verbose = 2\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b5a348-8f19-43d7-b96d-764b239959e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining_history = model.fit(\\n    training_dataset,\\n    epochs = epochs,\\n    validation_data = validation_dataset,\\n    callbacks=[early_stop],\\n    verbose = 2\\n)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "training_history = model.fit(\n",
    "    training_dataset,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_dataset,\n",
    "    callbacks=[early_stop],\n",
    "    verbose = 2\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ceea5-9f80-4011-aeb4-9951bc88ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 - 3s - 116ms/step - accuracy: 0.4888 - loss: 0.6975 - val_accuracy: 0.5638 - val_loss: 0.6900 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "27/27 - 1s - 42ms/step - accuracy: 0.5406 - loss: 0.6868 - val_accuracy: 0.4362 - val_loss: 0.7054 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.6631 - loss: 0.6344 - val_accuracy: 0.6702 - val_loss: 0.6337 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.6949 - loss: 0.5823 - val_accuracy: 0.6596 - val_loss: 0.6103 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "27/27 - 1s - 44ms/step - accuracy: 0.7244 - loss: 0.5699 - val_accuracy: 0.6702 - val_loss: 0.6025 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.7550 - loss: 0.5296 - val_accuracy: 0.7234 - val_loss: 0.5198 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.7644 - loss: 0.4999 - val_accuracy: 0.7660 - val_loss: 0.5145 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.7585 - loss: 0.5229 - val_accuracy: 0.7660 - val_loss: 0.5214 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.7538 - loss: 0.4912 - val_accuracy: 0.7872 - val_loss: 0.5634 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "27/27 - 1s - 47ms/step - accuracy: 0.7927 - loss: 0.4641 - val_accuracy: 0.8298 - val_loss: 0.4318 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8269 - loss: 0.4014 - val_accuracy: 0.8511 - val_loss: 0.3682 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8163 - loss: 0.4049 - val_accuracy: 0.8404 - val_loss: 0.4428 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8363 - loss: 0.3854 - val_accuracy: 0.8511 - val_loss: 0.3520 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8492 - loss: 0.3628 - val_accuracy: 0.8511 - val_loss: 0.3256 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8304 - loss: 0.3717 - val_accuracy: 0.8936 - val_loss: 0.3001 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8516 - loss: 0.3747 - val_accuracy: 0.8511 - val_loss: 0.3405 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8481 - loss: 0.3418 - val_accuracy: 0.8617 - val_loss: 0.4021 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8634 - loss: 0.3230 - val_accuracy: 0.8617 - val_loss: 0.3437 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8433 - loss: 0.3539 - val_accuracy: 0.8830 - val_loss: 0.2870 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "27/27 - 1s - 42ms/step - accuracy: 0.8728 - loss: 0.3065 - val_accuracy: 0.9043 - val_loss: 0.2947 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8751 - loss: 0.2799 - val_accuracy: 0.8723 - val_loss: 0.3039 - learning_rate: 5.0000e-05\n",
      "Epoch 22/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8881 - loss: 0.2736 - val_accuracy: 0.8617 - val_loss: 0.2974 - learning_rate: 5.0000e-05\n",
      "Epoch 23/100\n",
      "27/27 - 1s - 49ms/step - accuracy: 0.8693 - loss: 0.2917 - val_accuracy: 0.8830 - val_loss: 0.2915 - learning_rate: 5.0000e-05\n",
      "Epoch 24/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8857 - loss: 0.2651 - val_accuracy: 0.8936 - val_loss: 0.2894 - learning_rate: 5.0000e-05\n",
      "Epoch 25/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8940 - loss: 0.2575 - val_accuracy: 0.8617 - val_loss: 0.2972 - learning_rate: 5.0000e-05\n",
      "Epoch 26/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8881 - loss: 0.2862 - val_accuracy: 0.8936 - val_loss: 0.2774 - learning_rate: 5.0000e-05\n",
      "Epoch 27/100\n",
      "27/27 - 1s - 44ms/step - accuracy: 0.8963 - loss: 0.2640 - val_accuracy: 0.8830 - val_loss: 0.2864 - learning_rate: 5.0000e-05\n",
      "Epoch 28/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8905 - loss: 0.2519 - val_accuracy: 0.8830 - val_loss: 0.2833 - learning_rate: 5.0000e-05\n",
      "Epoch 29/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.9034 - loss: 0.2560 - val_accuracy: 0.8936 - val_loss: 0.2816 - learning_rate: 5.0000e-05\n",
      "Epoch 30/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.9034 - loss: 0.2554 - val_accuracy: 0.8723 - val_loss: 0.2932 - learning_rate: 5.0000e-05\n",
      "Epoch 31/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8987 - loss: 0.2553 - val_accuracy: 0.8830 - val_loss: 0.2910 - learning_rate: 5.0000e-06\n",
      "Epoch 32/100\n",
      "27/27 - 1s - 43ms/step - accuracy: 0.8857 - loss: 0.2610 - val_accuracy: 0.8830 - val_loss: 0.2905 - learning_rate: 5.0000e-06\n",
      "Epoch 33/100\n",
      "27/27 - 1s - 47ms/step - accuracy: 0.8940 - loss: 0.2570 - val_accuracy: 0.8830 - val_loss: 0.2884 - learning_rate: 5.0000e-06\n",
      "Epoch 34/100\n",
      "27/27 - 1s - 51ms/step - accuracy: 0.8893 - loss: 0.2586 - val_accuracy: 0.8830 - val_loss: 0.2862 - learning_rate: 5.0000e-06\n",
      "Epoch 35/100\n",
      "27/27 - 1s - 50ms/step - accuracy: 0.8893 - loss: 0.2669 - val_accuracy: 0.8936 - val_loss: 0.2882 - learning_rate: 5.0000e-06\n",
      "Epoch 36/100\n",
      "27/27 - 1s - 47ms/step - accuracy: 0.9011 - loss: 0.2416 - val_accuracy: 0.8936 - val_loss: 0.2863 - learning_rate: 5.0000e-06\n",
      "Epoch 37/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.9011 - loss: 0.2408 - val_accuracy: 0.8830 - val_loss: 0.2847 - learning_rate: 5.0000e-06\n",
      "Epoch 38/100\n",
      "27/27 - 1s - 44ms/step - accuracy: 0.8975 - loss: 0.2581 - val_accuracy: 0.8830 - val_loss: 0.2836 - learning_rate: 5.0000e-06\n",
      "Epoch 39/100\n",
      "27/27 - 1s - 44ms/step - accuracy: 0.8822 - loss: 0.2641 - val_accuracy: 0.8936 - val_loss: 0.2846 - learning_rate: 5.0000e-06\n",
      "Epoch 40/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8869 - loss: 0.2693 - val_accuracy: 0.8936 - val_loss: 0.2853 - learning_rate: 5.0000e-06\n",
      "Epoch 41/100\n",
      "27/27 - 1s - 48ms/step - accuracy: 0.8822 - loss: 0.2707 - val_accuracy: 0.8936 - val_loss: 0.2850 - learning_rate: 5.0000e-07\n",
      "Epoch 42/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8893 - loss: 0.2517 - val_accuracy: 0.8936 - val_loss: 0.2851 - learning_rate: 5.0000e-07\n",
      "Epoch 43/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8822 - loss: 0.2510 - val_accuracy: 0.8936 - val_loss: 0.2850 - learning_rate: 5.0000e-07\n",
      "Epoch 44/100\n",
      "27/27 - 1s - 49ms/step - accuracy: 0.8999 - loss: 0.2591 - val_accuracy: 0.8936 - val_loss: 0.2848 - learning_rate: 5.0000e-07\n",
      "Epoch 45/100\n",
      "27/27 - 1s - 48ms/step - accuracy: 0.8905 - loss: 0.2581 - val_accuracy: 0.8936 - val_loss: 0.2847 - learning_rate: 5.0000e-07\n",
      "Epoch 46/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8963 - loss: 0.2666 - val_accuracy: 0.8936 - val_loss: 0.2846 - learning_rate: 5.0000e-07\n",
      "Epoch 47/100\n",
      "27/27 - 1s - 48ms/step - accuracy: 0.8999 - loss: 0.2491 - val_accuracy: 0.8936 - val_loss: 0.2846 - learning_rate: 5.0000e-07\n",
      "Epoch 48/100\n",
      "27/27 - 1s - 51ms/step - accuracy: 0.8975 - loss: 0.2605 - val_accuracy: 0.8936 - val_loss: 0.2844 - learning_rate: 5.0000e-07\n",
      "Epoch 49/100\n",
      "27/27 - 1s - 50ms/step - accuracy: 0.8857 - loss: 0.2674 - val_accuracy: 0.8936 - val_loss: 0.2842 - learning_rate: 5.0000e-07\n",
      "Epoch 50/100\n",
      "27/27 - 1s - 48ms/step - accuracy: 0.9069 - loss: 0.2446 - val_accuracy: 0.8936 - val_loss: 0.2842 - learning_rate: 5.0000e-07\n",
      "Epoch 51/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8963 - loss: 0.2694 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 52/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8940 - loss: 0.2564 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 53/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8916 - loss: 0.2504 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 54/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8916 - loss: 0.2503 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 55/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.9011 - loss: 0.2466 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 56/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8999 - loss: 0.2585 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 57/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.9011 - loss: 0.2379 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 58/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8928 - loss: 0.2587 - val_accuracy: 0.8936 - val_loss: 0.2841 - learning_rate: 5.0000e-08\n",
      "Epoch 59/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8963 - loss: 0.2505 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-08\n",
      "Epoch 60/100\n",
      "27/27 - 1s - 49ms/step - accuracy: 0.8905 - loss: 0.2524 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-08\n",
      "Epoch 61/100\n",
      "27/27 - 1s - 49ms/step - accuracy: 0.9022 - loss: 0.2532 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 62/100\n",
      "27/27 - 1s - 50ms/step - accuracy: 0.9022 - loss: 0.2580 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 63/100\n",
      "27/27 - 1s - 47ms/step - accuracy: 0.8905 - loss: 0.2535 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 64/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8928 - loss: 0.2421 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 65/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8940 - loss: 0.2467 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 66/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.9022 - loss: 0.2371 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 67/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8975 - loss: 0.2512 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 68/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8963 - loss: 0.2506 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 69/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.9022 - loss: 0.2312 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 70/100\n",
      "27/27 - 1s - 48ms/step - accuracy: 0.9128 - loss: 0.2462 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-09\n",
      "Epoch 71/100\n",
      "27/27 - 1s - 47ms/step - accuracy: 0.9081 - loss: 0.2426 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 72/100\n",
      "27/27 - 1s - 47ms/step - accuracy: 0.8940 - loss: 0.2706 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 73/100\n",
      "27/27 - 1s - 51ms/step - accuracy: 0.9058 - loss: 0.2472 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 74/100\n",
      "27/27 - 1s - 54ms/step - accuracy: 0.8940 - loss: 0.2527 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 75/100\n",
      "27/27 - 1s - 51ms/step - accuracy: 0.8893 - loss: 0.2606 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 76/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.9058 - loss: 0.2279 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 77/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8928 - loss: 0.2612 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 78/100\n",
      "27/27 - 1s - 48ms/step - accuracy: 0.8775 - loss: 0.2768 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 79/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8893 - loss: 0.2516 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 80/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.9046 - loss: 0.2451 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-10\n",
      "Epoch 81/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8893 - loss: 0.2491 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-11\n",
      "Epoch 82/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8834 - loss: 0.2630 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-11\n",
      "Epoch 83/100\n",
      "27/27 - 1s - 46ms/step - accuracy: 0.8963 - loss: 0.2604 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-11\n",
      "Epoch 84/100\n",
      "27/27 - 1s - 45ms/step - accuracy: 0.8940 - loss: 0.2529 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-11\n",
      "Epoch 85/100\n",
      "27/27 - 1s - 50ms/step - accuracy: 0.8881 - loss: 0.2530 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-11\n",
      "Epoch 86/100\n",
      "27/27 - 1s - 49ms/step - accuracy: 0.8846 - loss: 0.2639 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-11\n",
      "Epoch 87/100\n",
      "27/27 - 1s - 48ms/step - accuracy: 0.8963 - loss: 0.2574 - val_accuracy: 0.8936 - val_loss: 0.2840 - learning_rate: 5.0000e-11\n",
      "Epoch 88/100\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    training_dataset,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_dataset,\n",
    "    callbacks = [lr_callback],\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32643e-ba36-4ab6-bf3b-43313b52bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#model.save('gender_recognition_project04_v10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ce52e-7f7c-47c7-9d63-f8d21a4ef5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16344a-bbc7-4ed5-a01e-39b651f802c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history = pd.DataFrame(model.history.history)\n",
    "result_history.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8df04-5bbc-4d47-a131-1e4a3a1c7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history[['loss', 'val_loss']].plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b61e9e-deaf-4f91-8b90-d23082a18b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_history[['accuracy', 'val_accuracy']].plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b259fcb-df40-4d21-a911-032373c25358",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "print(model.evaluate(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce3add-a314-4d29-91ea-76cb3ba57cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in validation_dataset])\n",
    "y_pred_prob = model.predict(validation_dataset)\n",
    "# Convert probabilities to class labels (0:Female or 1:Male)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=['Female', 'Male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063526cc-e2a0-4c8c-b01c-47ae3654a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "img_size = img_size\n",
    "model = tf.keras.models.load_model(\"gender_recognition_project04_v10.h5\")\n",
    "\n",
    "# Load your personal image if you are interested to predict:\n",
    "your_image_path = \"D:\\\\Hossein's desktop files in Microsoft Studio Laptop\\\\Personal Photos\\\\Hossein_10.jpg\"\n",
    "\n",
    "img = load_img(your_image_path, target_size=(img_size, img_size))\n",
    "final_img = img_to_array(img)\n",
    "# Adding a batch dimension:\n",
    "final_img = np.expand_dims(final_img, axis=0)\n",
    "prediction = model.predict(final_img)\n",
    "result = \"Female\" if prediction > 0.5 else \"Male\"\n",
    "if result==\"Female\":\n",
    "    confidence = (model.predict(final_img)[0][0])*100\n",
    "else:\n",
    "    confidence = (1-model.predict(final_img)[0][0])*100\n",
    "print(f\"Prediction result: {result} (confidence= {confidence:.2f} %)\")\n",
    "\n",
    "# Visualize CNN Layers\n",
    "successive_feature_maps = visualization_model.predict(final_img)\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    if len(feature_map.shape) == 4:  # Only visualize conv/maxpool layers\n",
    "        n_features = feature_map.shape[-1]  # Number of filters\n",
    "        size = feature_map.shape[1]  # Feature map size\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "\n",
    "        for i in range(n_features):\n",
    "            x = feature_map[0, :, :, i]\n",
    "            x -= x.mean()\n",
    "            x /= (x.std() + 1e-8)  # Normalize\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')  # Convert to image format\n",
    "            display_grid[:, i * size: (i + 1) * size] = x\n",
    "\n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='cividis')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199738b-2405-4223-9eae-21b5840224a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a87fb2-d828-420e-883f-709ca46ba4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb26553-bde6-4c23-ba84-69763691803d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
